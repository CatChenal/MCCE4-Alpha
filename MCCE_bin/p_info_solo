#!/usr/bin/env python

from collections import defaultdict
from datetime import datetime, timezone
import re
import subprocess
import sys
import os

# Add the parent directory to the Python path
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, parent_dir)

# now we can import our constants
from mcce4.constants import ALL_RES, IONIZABLE_RES, POLAR_RES


# FIX docstring
def line_counter(file_data: str, source_mcce: bool = False) -> tuple:
    """Accepts a string of text and returns counts for # of waters, ligands, and amino acids

    Args:
        file_data (string): file data in text form
        source_mcce ?????????????????????

    Returns:
        list: A list of strings, each containing the data for one chain.
    """

    file_data_lines = file_data.splitlines()
    waters = 0
    aa = 0
    non_aa = 0
    ligands = set()

    for this_line in file_data_lines:
        if " CA " in this_line and this_line.startswith("ATOM"):
            aa += 1
        if not source_mcce:
            if (
                this_line.startswith("HETATM") and "HOH" not in this_line
            ):  # HETATM indicates ligand or non-protein molecule
                res_name = this_line[17:20].strip()  # Residue name (ligand identifier)
                chain_id = this_line[21].strip()  # Chain identifier
                res_seq = this_line[22:26].strip()  # Residue sequence number
                ligands.add(
                    (res_name, chain_id, res_seq)
                )  # because set, only unique combinations are added
            if "HOH" in this_line and "HETATM" in this_line:
                waters += 1
        else:
            if this_line.startswith("HETATM") and "HOH" not in this_line:
                res_name = this_line[17:20].strip()  # Residue name (ligand identifier)
                chain_id = this_line[21].strip()  # Chain identifier
                res_seq = this_line[22:29].strip()  # seq id is longer for step1_out
                # add to set of ligands, yielding no dups:
                ligands.add((res_name, chain_id, res_seq))
            if (
                this_line.startswith("HETATM")
                and "HOH" in this_line
                and " O " in this_line
            ):
                waters += 1
        if this_line.startswith("HETATM") or this_line.startswith("ATOM"):
            residue_name = this_line[17:20].strip()

            if this_line.startswith("ATOM") and residue_name not in ALL_RES:
                # Count standard amino acids based on residue name
                non_aa += 1

    return waters, ligands, aa


def display_table(data: list, graph_name: str = "Total") -> None:
    """Takes in a 3 x 3 list of data and prints a nicely formatted table, which displays
    amino acid, ligand, and water counts for the total PDB file and its chains.

    Args:
        data (3 x 3 list): Path to the PDB file.
        graph_name (str): what the top-left of the graph says, change it for files with
                          multiple chains
    """

    if len(data) != 3 or any(len(row) != 3 for row in data):
        raise ValueError("Input data must be a 3x3 matrix.")

    # Add headers and footers to create a 4x4 table
    table_data = [
        [graph_name, "PDB Count", "MCCE Count", "Difference"],  # Header row
        ["Amino Acids"] + data[0],  # First data row
        ["Ligands"] + data[1],  # Second data row
        ["Waters"] + data[2],  # Third data row
    ]

    # Determine column widths
    col_widths = [max(len(str(row[col])) for row in table_data)
                  for col in range(len(table_data[0]))]

    # Build the table without borders
    table = []
    for row in table_data:
        row_line = "     ".join(
            f"{str(row[col]).ljust(col_widths[col])}" for col in range(len(row))
        )
        table.append(row_line)

    # Print the table
    print("\n".join(table))


def classify_amino_acids():
    """Classify amino acids into ionizable, polarized, and hydrophobic categories.

    Returns:
        dict: A dictionary with amino acid classifications.
    """
    return {
        "ionizable":
            ["ARG", "HIS", "LYS", "ASP", "GLU"],
        "polar":
            ["SER", "THR", "ASN", "GLN", "CYS", "TYR"],
        "hydrophobic": 
            ["ALA", "VAL", "LEU", "ILE", "MET", "PHE", "TRP", "PRO", "GLY"],
    }


def count_amino_acids(pdb_file):
    """Counts occurrences of standard amino acids in a PDB file, divided into three groups.

    Args:
        pdb_file (str): Path to the PDB file.

    Returns:
        dict: A dictionary with counts of amino acids in each category."""
    amino_acid_classes = classify_amino_acids()
    counts = defaultdict(int)

    with open(pdb_file, "r") as file:
        for line in file:
            # Only process lines starting with 'ATOM' with " CA " in them
            if line.startswith("ATOM") and " CA " in line:
                res_name = line[17:20].strip()  # Residue name is in columns 18-20
                for category, residues in amino_acid_classes.items():
                    if res_name in residues:
                        counts[category + ":" + res_name] += 1
                        break

    # Organize counts into categories
    categorized_counts = {category: {} for category in amino_acid_classes}
    for key, count in counts.items():
        category, residue = key.split(":")
        categorized_counts[category][residue] = count

    # Prepare column headers and sort by count in descending order
    ionizable = sorted(
        categorized_counts["ionizable"].items(), key=lambda x: x[1], reverse=True
    )
    polar = sorted(
        categorized_counts["polar"].items(), key=lambda x: x[1], reverse=True
    )
    hydrophobic = sorted(
        categorized_counts["hydrophobic"].items(), key=lambda x: x[1], reverse=True
    )

    # Calculate total counts for each category
    total_ionizable = sum(count for _, count in ionizable)
    total_polar = sum(count for _, count in polar)
    total_hydrophobic = sum(count for _, count in hydrophobic)

    # Determine the maximum number of rows
    max_rows = max(len(ionizable), len(polar), len(hydrophobic))

    print("Amino Acid Counts (Total ):")
    print(f"{'Ionizable':<20}{'Polar':<20}{'Hydrophobic':<20}")
    print("-" * 51)

    for i in range(max_rows):
        ionizable_res = (
            f"{ionizable[i][0]}: {ionizable[i][1]}" if i < len(ionizable) else ""
        )
        polar_res = (
            f"{polar[i][0]}: {polar[i][1]}" if i < len(polar) else ""
        )
        hydrophobic_res = (
            f"{hydrophobic[i][0]}: {hydrophobic[i][1]}" if i < len(hydrophobic) else ""
        )
        print(f"{ionizable_res:<20}{polar_res:<20}{hydrophobic_res:<20}")

    print("-" * 51)
    print(f"Total: {total_ionizable:<20}Total: {total_polar:<20}Total: {total_hydrophobic:<20}")


def count_missing_atoms(line: str) -> int:
    """helper function for parse_log_data.

    Args:
        line (str): line of text we want to count atoms from

    Returns:
        int: number of atoms in that line"""

    match = re.search(r"Missing heavy atoms.*?:\s*(.+?)\.", line)
    if match:
        atom_list = match.group(1).split(", ")
        return len(atom_list)
    return 0


def parse_log_data(log_data: str) -> tuple:

    rules = {}  # dictionary to contain rules and examples for how molecules are renamed
    err_top_files = ""
    how_many_atoms_change = 0
    missing_atoms = 0
    NTR_line = ""
    CTR_line = ""
    prox_ligands = ""
    log_data = log_data.splitlines()

    for line in log_data:

        if "Distance below bond threshold" in line:
            prox_ligands += "   " + line + "\n"
        if "Labeling" in line and "NTR" in line:
            NTR_line += line + "\n"  # account for multiple NTR changes
        if "Labeling" in line and "NTG" in line:
            NTR_line += line + " (NTR for GYL)" + "\n"
        if "Labeling" in line and "CTR" in line:
            CTR_line += line + "\n"

        match = re.match(r"\s*Renaming \"(.*?)\" to \"(.*?)\"", line)
        if match:
            how_many_atoms_change += 1
            original, renamed = match.groups()

            # Determine the rule by finding the difference between original and renamed
            rule = ""
            for i, (o_char, r_char) in enumerate(zip(original, renamed)):
                if o_char != r_char:
                    rule += f"Position {i}: '{o_char}' -> '{r_char}'\n"

            if len(original) != len(renamed):
                rule += f"Length difference: Original({len(original)}) -> Renamed({len(renamed)})\n"

            # Normalize the rule description
            rule = rule.strip()

            # Store one example for each unique rule
            if rule not in rules:
                rules[rule] = (original, renamed)

        if "Error!" in line:
            err_top_files += line + "\n"

        # count missing atoms, but don't count the line saying "Missing heavy atoms detected."
        if "Missing" in line and "detected" not in line:
            missing_atoms += count_missing_atoms(line)

    return (
        NTR_line,
        CTR_line,
        missing_atoms,
        how_many_atoms_change,
        rules,
        prox_ligands,
        err_top_files,
    )


def parse_pdb_chains(pdb_file: str) -> list:
    """Identifies and extracts individual chains from a PDB file.

    Args:
        pdb_file (str): Path to the PDB file.

    Returns:
        list: A list of strings, each containing the data for one chain."""

    chains = {}

    try:
        with open(pdb_file, "r") as file:
            for line in file:
                if line.startswith(("ATOM", "HETATM")):
                    chain_id = line[
                        21
                    ]  # Chain identifier is in column 22 (0-indexed: 21)
                    if chain_id not in chains:
                        chains[chain_id] = []
                    chains[chain_id].append(line)

        # Convert the chains dictionary to a list of strings
        chain_data = ["".join(chains[chain_id]) for chain_id in chains]

        return chain_data, list(
            chains.keys()
        )  # return the chains, and a list of the chains' names

    except FileNotFoundError:
        print(f"Error: File '{pdb_file}' not found.")
        return []
    except Exception as e:
        print(f"An error occurred: {e}")
        return []


def count_ligands_by_chain(ligands, file_name, full_prot=False):
    """Print the type of ligands and how many there are.

    Args:
        ligands (list):
        pdb_file (str): Path to the PDB file."""

    if ligands:  # only bother printing anything if the ligand set is non-empty
        if not full_prot:
            chain_ligands = defaultdict(lambda: defaultdict(int)) # non-ideal data type, fix later

            for ligand, chain, _ in ligands:
                chain_ligands[chain][ligand] += 1

            # below portion should print ONLY if there are multiple chains.
            for chain, ligand_counts in chain_ligands.items():
                print(f"\n      Ligand counts for chain {chain}, in {file_name}:")
                for ligand, count in ligand_counts.items():
                    print(f"          {ligand}: {count}")

        else:  # print total count

            total_ligands = defaultdict(int)

            for ligand, _, __ in ligands:
                total_ligands[ligand] += 1

            print(f"\n      Total ligand counts for {file_name}:")
            for ligand, count in total_ligands.items():
                print(f"          {ligand}: {count}")


def closer():
    """Close out function, give the current time.
    """
    utc_dt = datetime.now(timezone.utc)
    print(
        "\np_info was run at local time {}".format(
            utc_dt.astimezone().strftime("%a %b %d %Y, %I:%M%p")
        )
    )
    print("\nThanks for using p_info! It's free!\n")


if __name__ == "__main__":

    try:
        input_file = sys.argv[1]

        # take the first terminal argument after the Python script is called.
        # WHAT IF FILE NOT LOWERCASE? Include option to turn the .lower() off
        if input_file.lower() == "-h":
            print("p_info summarizes useful information about .pdb files, including residue,",
                  "water, amino acid, and ligand counts.\n", "p_info reads MCCE created files",
                  "and the chosen PDB file. If the desired files do not exist for the desired",
                  "pdb file at runtime, p_info will run step 1 and create the files, then run as",
                  "usual.\nUse like 'p_info 4lzt.pdb'.\np_info expects that the file to-be-run be",
                  "in the present working directory."
                  )
            sys.exit(1)
    except IndexError:
        print("\nPlease include the PDB file after the executable, e.g. 'p_info 4lzt.pdb'",
              "This is case-sensitive. Use command 'p_info -h' for more help.\n")
        sys.exit(1)

    if ".pdb" not in input_file:
        input_file = input_file + ".pdb"
    # maybe include multiple model warning- MCCE expects 1 model pdb file

    try:
        with open(input_file) as file:
            # to get numbers of waters, ligands, aa's in the protein file
            data = file.read()

        with open("step1_out.pdb") as file:
            # to get numbers of waters, ligands, aa's, post-step1 processing
            mcce_data = file.read()

        with open("run1.log") as file:
            # to identify where changes have occurred
            log_data = file.read()

        print(f"\nFound {input_file},", "its associated run1.log, and step1_out.pdb",
              "in the current directory.\n")

    except FileNotFoundError:  # run step1.py if we don't have its product files
        print(f"\np_info requires {input_file},",
              "its associated run1.log, and step1_out.pdb",
              "in the current directory.\n\nRunning step1.py...")

        script_path = subprocess.run(["which", "step1.py"],
                                     capture_output=True,
                                     text=True
                                     ).stdout.strip()
        if not script_path:
            print("The executable module 'step1.py' could not be found. ")
            sys.exit(1)

        process = subprocess.run([script_path, input_file],
                                stderr=subprocess.STDOUT,
                                stdout=open("run1.log", "a"),
                                close_fds=True,
                                text=True,
                                ) 

    try:
        # for how many waters, ligands, aa's, were in protein file
        with open(input_file) as file:
            data = file.read()
        # for how many waters, ligands, aa's, post-processing
        with open("step1_out.pdb") as file:
            mcce_data = file.read()
        # helps identify where changes have occurred
        with open("run1.log", "r") as file:
            log_data = file.read()

    except FileNotFoundError:
        print("Step 1 failed! Check files and try again, or report an error.")

    # get HOH, ligand names, and amino acid counts
    HOH_count, ligand_names, aa_count = line_counter(data)
    HOH_mcce_count, ligand_mcce_names, aa_mcce_count = line_counter(
        mcce_data, source_mcce=True
    )
    ligand_count = len(ligand_names)
    ligand_mcce_count = len(ligand_mcce_names)

    print("\np_info by Jared Suchomel, with contributions by Marilyn Gunner, Cat Chenal,",
          "and Junjun Mao! It's still in progress!\n",
          "### For the input " + input_file + ":\n")

    count_amino_acids(input_file)

    # format the data for the function to pick up
    interior_data = [
        [str(aa_count), str(aa_mcce_count), str(abs(aa_count - aa_mcce_count))],
        [
            str(ligand_count),
            str(ligand_mcce_count),
            str(abs(ligand_count - ligand_mcce_count)),
        ],
        [str(HOH_count), str(HOH_mcce_count), str(abs(HOH_count - HOH_mcce_count))],
    ]

    chains, chain_labels = parse_pdb_chains(input_file)
    print(f"\n### The PDB file has {len(chains)} chain(s).")

    display_table(interior_data)

    if len(chains) > 1:
        mcce_chains, _ = parse_pdb_chains("step1_out.pdb")
        for i, chain in enumerate(chains, start=1):
            print("")

            HOH_chain_count, ligand_chain_count, aa_chain_count = line_counter(chain)
            HOH_mcce_chain_count, ligand_mcce_chain_count, aa_mcce_chain_count = (
                line_counter(mcce_chains[i - 1], source_mcce=True)
            )  # adjust to 0-indexed
            chain_data = [
                [
                    str(aa_chain_count),
                    str(aa_mcce_chain_count),
                    str(abs(aa_chain_count - aa_mcce_chain_count)),
                ],
                [
                    str(len(ligand_chain_count)),
                    str(len(ligand_mcce_chain_count)),
                    str(abs(len(ligand_chain_count) - len(ligand_mcce_chain_count))),
                ],
                [
                    str(HOH_chain_count),
                    str(HOH_mcce_chain_count),
                    str(abs(HOH_chain_count - HOH_mcce_chain_count)),
                ],
            ]
            display_table(
                chain_data, graph_name="Chain " + str(chain_labels[i - 1])
            )  # again, adjust to 0-indexed

    print("\nWaters and ions stripped if 5% of their Surface Area is exposed to Solvent.")
    print("\nSAS exposure limit edited in 'run.prm' parameter (H2O_SASCUTOFF)")
    print("\nGroups that can be deleted listed in [ASK GEHAN]")
    print("\nNOTE: Default removes all waters. To retain buried waters, do a 'wet' run.")

    # NEED TO DETAIL WHAT IONS SPECIFICALLY ARE STRIPPED, INCLUDE EXPLICIT LIST
    (
        NTR_line,
        CTR_line,
        missing_atoms,
        how_many_atoms_change,
        rules,
        prox_ligands,
        err_top_files,
    ) = parse_log_data(log_data)

    print("\nThese residues have been modified:")
    print("\n### TERMINI:\n")
    print(NTR_line, CTR_line)
    print(missing_atoms, "missing atoms added. This number DOES NOT include atoms",
          "relabeled as NTR, or CTR. See run1.log for full list.\n",
          how_many_atoms_change, " atoms changed.")

    if not ligand_mcce_names:  # if ligand name list is empty, skip ligands
        print("\nNo ligands detected in step1_out.",
              "\nA list of all atoms that are modified can be found in run1.log.\n")
        closer()
        sys.exit()  # finish the program early

    print("\n### LIGANDS:\n")
    if len(chains) > 1:
        count_ligands_by_chain(ligand_mcce_names, "step1_out.pdb", full_prot=True)
    count_ligands_by_chain(ligand_mcce_names, "step1_out.pdb")
    print("\n" + prox_ligands + "\n      Groups are renamed or deleted relative to the input protein.\n")

    if bool(rules):
        print("      The rules for changes, and examples:\n")
        for rule, example in rules.items():
            print(f"      {example[0]} -> {example[1]}")
        print("\nA list of all atoms that are modified can be found in run1.log.")

    unique_ligand_names = [lig[0] for lig in ligand_mcce_names]

    # FIX:
    #    re-do this, need to make it so we're only examining ligands from step1_out.
    #    We don't care about ligands only in ori final
    # find shared ligands between list of ligands, ligands w/o topology files
    ligand_sifter = set(unique_ligand_names) & set(err_top_files.split())
    ligand_top = set(unique_ligand_names) - ligand_sifter
    if ligand_top:
        print("\nWe have topology files for these ligands:",
              "\n      TPLFOUND: ", ligand_top)

    if err_top_files:
        print("\nWe do not have topology files for these ligands:"
              "\n      NOTPL: ", end='')
        # only print the 3-char names of the residues:
        print([line[-3:] for line in err_top_files.splitlines()],
              "\n\nYou can remove them from the input pdb file if desired, and",
              "\n      (1) Continue as is: Atoms for these ligands are set to have",
              "zero charge and zero vdw in new.tpl.",
              "\n      (2) Repeat step1 with ligands removed: Remove ligands from",
              "input pdb and redo step1.",
              "\n      (3) Repeat step1 after creating topology files for ligands."
              )

    closer()
