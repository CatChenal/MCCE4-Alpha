#!/usr/bin/env python

"""
Summarize useful information from protein file and step 1 output.
"""

import argparse
from collections import defaultdict
from datetime import datetime, timezone
from pathlib import Path
import re
import os
import shutil
import subprocess
import sys

from mcce4.constants import ALL_RES

def line_counter(file_data: str, source_mcce: bool = False) -> tuple:
    """Accepts a string of text and returns counts for # of waters, ligands, and amino acids

    Args:
        file_data (string): file data in text form
        source_mcce (bool): should be True if referencing step1_out.pdb

    Returns:
        list: A list of strings, each containing the data for one chain.
    """

    file_data_lines = file_data.splitlines()
    waters = 0
    aa = 0
    non_aa = 0
    ligands = set()

    for this_line in file_data_lines:
        if " CA " in this_line and this_line.startswith("ATOM"):
            aa += 1
        if not source_mcce:
            if (
                this_line.startswith("HETATM") and "HOH" not in this_line
            ):  # HETATM indicates ligand or non-protein molecule
                res_name = this_line[17:20].strip()  # Residue name (ligand identifier)
                chain_id = this_line[21].strip()  # Chain identifier
                res_seq = this_line[22:26].strip()  # Residue sequence number
                ligands.add(
                    (res_name, chain_id, res_seq)
                )  # because set, only unique combinations are added
            if "HOH" in this_line and "HETATM" in this_line:
                waters += 1
        else:
            if this_line.startswith("HETATM") and "HOH" not in this_line:
                res_name = this_line[17:20].strip()  # Residue name (ligand identifier)
                chain_id = this_line[21].strip()  # Chain identifier
                res_seq = this_line[22:29].strip()  # seq id is longer for step1_out
                # add to set of ligands, yielding no dups:
                ligands.add((res_name, chain_id, res_seq))
            if (
                this_line.startswith("HETATM")
                and "HOH" in this_line
                and " O " in this_line
            ):
                waters += 1
        if this_line.startswith("HETATM") or this_line.startswith("ATOM"):
            residue_name = this_line[17:20].strip()

            if this_line.startswith("ATOM") and residue_name not in ALL_RES:
                # Count standard amino acids based on residue name
                non_aa += 1

    return waters, ligands, aa

def display_table(data: list, graph_name: str = "Total") -> None:
    """Takes in a 3 x 3 list of data and prints a nicely formatted table, which displays
    amino acid, ligand, and water counts for the total PDB file and its chains.

    Args:
        data (3 x 3 list): Path to the PDB file.
        graph_name (str): what the top-left of the graph says, change it for files with
                          multiple chains
    """

    if len(data) != 3 or any(len(row) != 3 for row in data):
        raise ValueError("Input data must be a 3x3 matrix.")

    # Add headers and footers to create a 4x4 table
    table_data = [
        [graph_name, "PDB Count", "MCCE Count", "Difference"],  # Header row
        ["Amino Acids"] + data[0],  # First data row
        ["Ligands"] + data[1],  # Second data row
        ["Waters"] + data[2],  # Third data row
    ]

    # Determine column widths
    col_widths = [max(len(str(row[col])) for row in table_data)
                  for col in range(len(table_data[0]))]

    # Build the table without borders
    table = []
    for row in table_data:
        row_line = "     ".join(
            f"{str(row[col]).ljust(col_widths[col])}" for col in range(len(row))
        )
        table.append(row_line)

    # Print the table
    print("\n".join(table))

def classify_amino_acids():
    """Classify amino acids into ionizable, polarized, and hydrophobic categories.

    Returns:
        dict: A dictionary with amino acid classifications.
    """
    return {
        "ionizable":
            ["ARG", "HIS", "LYS", "ASP", "GLU"],
        "polar":
            ["SER", "THR", "ASN", "GLN", "CYS", "TYR"],
        "hydrophobic":
            ["ALA", "VAL", "LEU", "ILE", "MET", "PHE", "TRP", "PRO", "GLY"],
    }

def count_amino_acids(pdb_file):
    """Counts occurrences of standard amino acids in a PDB file, divided into three groups.

    Args:
        pdb_file (str): Path to the PDB file.

    Returns:
        dict: A dictionary with counts of amino acids in each category."""
    amino_acid_classes = classify_amino_acids()
    counts = defaultdict(int)

    with open(pdb_file, "r") as file:
        for line in file:
            # Only process lines starting with 'ATOM' with " CA " in them
            if line.startswith("ATOM") and " CA " in line:
                res_name = line[17:20].strip()  # Residue name is in columns 18-20
                for category, residues in amino_acid_classes.items():
                    if res_name in residues:
                        counts[category + ":" + res_name] += 1
                        break

    # Organize counts into categories
    categorized_counts = {category: {} for category in amino_acid_classes}
    for key, count in counts.items():
        category, residue = key.split(":")
        categorized_counts[category][residue] = count

    # Prepare column headers and sort by count in descending order
    ionizable = sorted(
        categorized_counts["ionizable"].items(), key=lambda x: x[1], reverse=True
    )
    polar = sorted(
        categorized_counts["polar"].items(), key=lambda x: x[1], reverse=True
    )
    hydrophobic = sorted(
        categorized_counts["hydrophobic"].items(), key=lambda x: x[1], reverse=True
    )

    # Calculate total counts for each category
    total_ionizable = sum(count for _, count in ionizable)
    total_polar = sum(count for _, count in polar)
    total_hydrophobic = sum(count for _, count in hydrophobic)
    total_aa = total_ionizable + total_polar + total_hydrophobic

    # Determine the maximum number of rows
    max_rows = max(len(ionizable), len(polar), len(hydrophobic))

    print(f"Amino Acid Counts (of {total_aa} Total):")
    print(f"{'Ionizable':<20}{'Polar':<20}{'Hydrophobic':<20}")
    print("-" * 51)

    for i in range(max_rows):
        ionizable_res = (
            f"{ionizable[i][0]}: {ionizable[i][1]}" if i < len(ionizable) else ""
        )
        polar_res = (
            f"{polar[i][0]}: {polar[i][1]}" if i < len(polar) else ""
        )
        hydrophobic_res = (
            f"{hydrophobic[i][0]}: {hydrophobic[i][1]}" if i < len(hydrophobic) else ""
        )
        print(f"{ionizable_res:<20}{polar_res:<20}{hydrophobic_res:<20}")

    print("-" * 51)
    print(f"Total: {total_ionizable:<11}Total: {total_polar:<13}Total: {total_hydrophobic:<12}\n")

# must be rewritten, atoms are no longer written out line-by-line
def count_missing_atoms(line: str) -> int:
    """helper function for parse_log_data.

    Args:
        line (str): line of text we want to count atoms from

    Returns:
        int: number of atoms in that line"""

    match = re.search(r"Missing heavy atoms.*?:\s*(.+?)\.", line)
    if match:
        atom_list = match.group(1).split(", ")
        return len(atom_list)
    return 0

def parse_log_data(log_data: str) -> tuple:

    rules = {}  # dictionary to contain rules and examples for how molecules are renamed
    err_top_files = ""
    how_many_atoms_change = 0
    missing_atoms = 0
    NTR_line = ""
    CTR_line = ""
    prox_ligands = ""
    log_data = log_data.splitlines()

    for line in log_data:

        if "Distance below bond threshold" in line:
            prox_ligands += "   " + line + "\n"
        if "Labeling" in line and "NTR" in line:
            NTR_line += line + "\n"  # account for multiple NTR changes
        if "Labeling" in line and "NTG" in line:
            NTR_line += line + " (NTR for GYL)" + "\n"
        if "Labeling" in line and "CTR" in line:
            CTR_line += line + "\n"

        match = re.match(r"\s*Renaming \"(.*?)\" to \"(.*?)\"", line)
        if match:
            how_many_atoms_change += 1
            original, renamed = match.groups()

            # Determine the rule by finding the difference between original and renamed
            rule = ""
            for i, (o_char, r_char) in enumerate(zip(original, renamed)):
                if o_char != r_char:
                    rule += f"Position {i}: '{o_char}' -> '{r_char}'\n"

            if len(original) != len(renamed):
                rule += f"Length difference: Original({len(original)}) -> Renamed({len(renamed)})\n"

            # Normalize the rule description
            rule = rule.strip()

            # Store one example for each unique rule
            if rule not in rules:
                rules[rule] = (original, renamed)

        if "Error!" in line:
            err_top_files += line + "\n"

        # count missing atoms, but don't count the line saying "Missing heavy atoms detected."
        if "Missing" in line and "detected" not in line:
            missing_atoms += count_missing_atoms(line)

    return (
        NTR_line,
        CTR_line,
        missing_atoms,
        how_many_atoms_change,
        rules,
        prox_ligands,
        err_top_files,
    )

def parse_pdb_chains(pdb_file: str) -> list:
    """Identifies and extracts individual chains from a PDB file.

    Args:
        pdb_file (str): Path to the PDB file.

    Returns:
        list: A list of strings, each containing the data for one chain."""

    chains = {}

    try:
        with open(pdb_file, "r") as file:
            for line in file:
                if line.startswith(("ATOM", "HETATM")):
                    chain_id = line[
                        21
                    ]  # Chain identifier is in column 22 (0-indexed: 21)
                    if chain_id not in chains:
                        chains[chain_id] = []
                    chains[chain_id].append(line)

        # Convert the chains dictionary to a list of strings
        chain_data = ["".join(chains[chain_id]) for chain_id in chains]

        return chain_data, list(
            chains.keys()
        )  # return the chains, and a list of the chains' names

    except FileNotFoundError:
        print(f"Error: File '{pdb_file}' not found.")
        return []
    except Exception as e:
        print(f"An error occurred: {e}")
        return []

def count_ligands_by_chain(ligands, file_name, full_prot=False):
    """Print the type of ligands and how many there are.

    Args:
        ligands (list):
        pdb_file (str): Path to the PDB file."""

    if ligands:  # only bother printing anything if the ligand set is non-empty
        if not full_prot:
            chain_ligands = defaultdict(lambda: defaultdict(int)) # non-ideal data type, fix later

            for ligand, chain, _ in ligands:
                chain_ligands[chain][ligand] += 1

            # below portion should print ONLY if there are multiple chains.
            for chain, ligand_counts in chain_ligands.items():
                print(f"\n      Ligand counts for chain {chain}, in {file_name}:")
                for ligand, count in ligand_counts.items():
                    print(f"          {ligand}: {count}")

        else:  # print total count

            total_ligands = defaultdict(int)

            for ligand, _, __ in ligands:
                total_ligands[ligand] += 1

            print(f"\n      Total ligand counts for {file_name}:")
            for ligand, count in total_ligands.items():
                print(f"          {ligand}: {count}")

def check_input_files(input_file: str):
    """Make sure give files exist. If they do not exist, try to execute step 1 so they do

    Args:
        input file (str): Path to the PDB file."""

    # maybe include multiple model warning- MCCE expects 1 model pdb file

    try:
        with open(input_file) as file:
            # to get numbers of waters, ligands, aa's in the protein file
            data = file.read()
    except FileNotFoundError:  # If we don't have source protein file, just stop
        print(f"\n{input_file} not found, aborting p_info...\n")
        sys.exit()
    try:
        with open("step1_out.pdb") as file:
            # to get numbers of waters, ligands, aa's, post-step1 processing
            mcce_data = file.read()

        with open("run1.log") as file:
            # to identify where changes have occurred
            log_data = file.read()

        print(f"\nFound {input_file},", "its associated run1.log, and step1_out.pdb",
              "in the current directory.")

    except FileNotFoundError:  # run step1.py if we don't have its product files
        print(f"\np_info requires {input_file},",
              "its associated run1.log, and step1_out.pdb",
              "in the current directory.\n\nRunning step1.py...")

        script_path = subprocess.run(["which", "step1.py"],
                                     capture_output=True,
                                     text=True
                                     ).stdout.strip()
        if not script_path:
            print("The executable module 'step1.py' could not be found. ")
            sys.exit(1)

        process = subprocess.run([script_path, input_file],
                                stderr=subprocess.STDOUT,
                                stdout=open("run1.log", "a"),
                                close_fds=True,
                                text=True,
                                )

    try:
        # for how many waters, ligands, aa's, were in protein file
        with open(input_file) as file:
            prot_data = file.read()
        # for how many waters, ligands, aa's, post-processing
        with open("step1_out.pdb") as file:
            mcce_data = file.read()
        # helps identify where changes have occurred
        with open("run1.log", "r") as file:
            log_data = file.read()

    except FileNotFoundError:
        print("\nStep 1 failed! Check files and try again, or report an error.\n")
        sys.exit()

    return prot_data, mcce_data, log_data

def table_summary(prot_data: str, mcce_data: str, input_file: str):
    """Create a table summarizing information about residue counts, ligands, and waters

    Args:
        prot_data (str): PDB file contents (we don't look at the header)
        mcce_data (str): step1_out contents (what did MCCE rename or change?)
        input file (str): name of PDB file

    Returns:
        ligand_mcce_names (list): names of ligands from step1_out.pdb"""

    # get HOH, ligand names, and amino acid counts
    HOH_count, ligand_names, aa_count = line_counter(prot_data)
    HOH_mcce_count, ligand_mcce_names, aa_mcce_count = line_counter(
        mcce_data, source_mcce=True
    )
    ligand_count = len(ligand_names)
    ligand_mcce_count = len(ligand_mcce_names)

    print("\np_info by Jared Suchomel, with contributions by Marilyn Gunner, Cat Chenal,",
          " and Junjun Mao! It's still in progress!\n",
          "\n### For the input " + str(input_file) + ":\n", sep="")

    count_amino_acids(input_file)

    # format the data for the function to pick up
    interior_data = [
        [str(aa_count), str(aa_mcce_count), str(abs(aa_count - aa_mcce_count))],
        [
            str(ligand_count),
            str(ligand_mcce_count),
            str(abs(ligand_count - ligand_mcce_count)),
        ],
        [str(HOH_count), str(HOH_mcce_count), str(abs(HOH_count - HOH_mcce_count))],
    ]
    
    display_table(interior_data)
    return ligand_mcce_names

def chain_summary(input_path: str):
    """Make sure needed files exist. If they do not exist, try to execute step 1 so 

    Args:
        input file (str): Path to the PDB file.

    Returns:
        ligand_mcce_names (list): names of ligands from step1_out.pdb"""

    chains, chain_labels = parse_pdb_chains(input_path)
    print(f"\n### The PDB file has {len(chains)} chain(s).")

    if len(chains) > 1:
        mcce_chains, _ = parse_pdb_chains("step1_out.pdb")
        for i, chain in enumerate(chains, start=1):
            print("")

            HOH_chain_count, ligand_chain_count, aa_chain_count = line_counter(chain)
            HOH_mcce_chain_count, ligand_mcce_chain_count, aa_mcce_chain_count = (
                line_counter(mcce_chains[i - 1], source_mcce=True)
            )  # adjust to 0-indexed
            chain_data = [
                [
                    str(aa_chain_count),
                    str(aa_mcce_chain_count),
                    str(abs(aa_chain_count - aa_mcce_chain_count)),
                ],
                [
                    str(len(ligand_chain_count)),
                    str(len(ligand_mcce_chain_count)),
                    str(abs(len(ligand_chain_count) - len(ligand_mcce_chain_count))),
                ],
                [
                    str(HOH_chain_count),
                    str(HOH_mcce_chain_count),
                    str(abs(HOH_chain_count - HOH_mcce_chain_count)),
                ],
            ]
            display_table(
                chain_data, graph_name="Chain " + str(chain_labels[i - 1])
            )  # again, adjust to 0-indexed

    print("\nWaters and ions stripped if 5% of their Surface Area is exposed to Solvent.")
    print("\nSAS exposure limit edited in 'run.prm' parameter (H2O_SASCUTOFF)")
    print("\nGroups that can be deleted listed in [ASK GEHAN]")
    print("\nNOTE: Default removes all waters. To retain buried waters, do a 'wet' run.")

    return chains

def ligands_and_modified_residues(log_data: str, ligand_mcce_names: list, chains: list):
    """Report on ligands and modified residues using the log from step 1. 

    Args:
        input file (str): Path to the PDB file.

    Returns:
        ligand_mcce_names (list): names of ligands from step1_out.pdb"""

    # NEED TO DETAIL WHAT IONS SPECIFICALLY ARE STRIPPED, INCLUDE EXPLICIT LIST
    (
        NTR_line,
        CTR_line,
        missing_atoms,
        how_many_atoms_change,
        rules,
        prox_ligands,
        err_top_files,
    ) = parse_log_data(log_data)

    print("\nThese residues have been modified:")
    print("\n### TERMINI:\n")
    print(NTR_line, CTR_line, sep="")
    print(missing_atoms, " missing atoms added. This number DOES NOT include atoms",
          " relabeled as NTR, or CTR. See run1.log for full list.\n",
          how_many_atoms_change, " atoms changed.", sep="")

    if NTR_line.count("NTR") > len(chains):
        print("WARNING! Found " + str(NTR_line.count("NTR")) + " NTRs inside " + str(len(chains)) + " chains.")

    if not ligand_mcce_names:  # if ligand name list is empty, skip ligands
        print("\nNo ligands detected in step1_out.",
              "\nA list of all atoms that are modified can be found in run1.log.\n")
    else:
        print("\n### LIGANDS:\n")
        if len(chains) > 1:
            count_ligands_by_chain(ligand_mcce_names, "step1_out.pdb", full_prot=True)
        count_ligands_by_chain(ligand_mcce_names, "step1_out.pdb")
        print("\n" + prox_ligands + "\n      Groups are renamed or deleted relative to the input protein.\n")

        if bool(rules):
            print("The rules for changes, and examples:\n")
            for rule, example in rules.items():
                print(f"      {example[0]} -> {example[1]}")
            print("\nA list of all atoms that are modified can be found in run1.log.")

        unique_ligand_names = [lig[0] for lig in ligand_mcce_names]

        # FIX:
        #    re-do this, need to make it so we're only examining ligands from step1_out.
        #    We don't care about ligands only in ori final
        # find shared ligands between list of ligands, ligands w/o topology files
        ligand_sifter = set(unique_ligand_names) & set(err_top_files.split())
        ligand_top = set(unique_ligand_names) - ligand_sifter
        if ligand_top:
            print("\nWe have topology files for these ligands:",
                  "\n      TPLFOUND: ", ligand_top)

        if err_top_files:
            print("\nWe do not have topology files for these ligands:"
                  "\n      NOTPL: ", end='')
            # only print the 3-char names of the residues:
            print([line[-3:] for line in err_top_files.splitlines()],
                  "\n\nYou can remove them from the input pdb file if desired, and",
                  "\n      (1) Continue as is: Atoms for these ligands are set to have",
                  "zero charge and zero vdw in new.tpl.",
                  "\n      (2) Repeat step1 with ligands removed: Remove ligands from",
                  "input pdb and redo step1.",
                  "\n      (3) Repeat step1 after creating topology files for ligands."
                  )

def closer():
    """Close out function, give the current time.
    """
    utc_dt = datetime.now(timezone.utc)
    print(
        "\np_info was run at local time {}".format(
            utc_dt.astimezone().strftime("%a %b %d %Y, %I:%M%p")
        )
    )
    print("\nThanks for using p_info! It's free!\n")

def get_pdb_files(input_path):
    """Collect PDB files from a source directory into their own respective directories.
    
    Args:
        input_path (str): Path to Directory w/PDB files
i
    Return:
        pdb_files (list): List of paths to PDB files"""

    pdb_files = []
    path = Path(input_path)
    if path.is_dir():
        pdb_files = list(path.glob("*.pdb"))
    elif path.is_file():
        found_pdb = False
        with open(path, 'r') as f:
            for line in f:
                file_path = Path(line.strip())
                if file_path.exists() and file_path.suffix == '.pdb':
                    pdb_files.append(file_path)
                    found_pdb = True
            if found_pdb == False:
                print("Could not find valid paths to '.pdb' files in the given file. Aborting...")
                return 0
    else:
        print("Invalid input: must be a directory with PDB files, or a text file containing paths to PDB files.")
        return 0
    return pdb_files

def process_pdb_file(pdb_file):
    """Process PDB files, output to p_info.log rather than terminal.
    
    Args:
        pdb_file (str): Path to PDB files

    Return:"""

    base_name = pdb_file.stem
    dir_name = Path(base_name)
    dir_name.mkdir(exist_ok=True)

    dest_pdb = dir_name / pdb_file.name
    shutil.copy(pdb_file, dest_pdb)

    log_file = dir_name / "p_info.log"
    original_stdout = sys.stdout
    original_stderr = sys.stderr
    original_cwd = os.getcwd()

    with open(log_file, "w") as log:
        sys.stdout = log
        sys.stderr = log
        try:
            os.chdir(dir_name)  # Redirect all file outputs to this folder
            main(dest_pdb.name)  # Use just the filename since cwd changed
        finally:
            os.chdir(original_cwd)
            sys.stdout = original_stdout
            sys.stderr = original_stderr

def main(input_path):
    """Collect and summarize all relevant data from a PDB file.
    """

    prot_data, mcce_data, log_data = check_input_files(input_path)
    ligand_mcce_names = table_summary(prot_data, mcce_data, input_path)
    chains = chain_summary(input_path)
    ligands_and_modified_residues(log_data, ligand_mcce_names, chains)

if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="p_info accepts a Protein Data Bank, or PDB file, and prints useful information about residue counts, ligands, etc."
    )
    parser.add_argument(
        "input_path",
        type=str,
        help="Path to a .pdb file"
    )

    args = parser.parse_args()
    input_path = args.input_path
    pdb_files = []

    if not os.path.exists(input_path):
        print("File/Directory not found! Aborting p_info...")

    if os.path.isfile(input_path) and input_path.lower().endswith(".pdb"):
        main(input_path)
        closer()

    if os.path.isdir(input_path):
        print("This is a directory.\n")
        pdb_files = get_pdb_files(input_path)
        if not pdb_files:
            print("No valid PDB files found.")

    for pdb_file in pdb_files:
        print(f"Processing {pdb_file}...")
        try:
            process_pdb_file(pdb_file)
        except Exception as e:
            print(f"Error processing {pdb_file}: {e}")
